# `Latent Prompt Tuning for Text Summarization`
paper link : https://arxiv.org/pdf/2304.05205.pdf

|Topic| Latent Prompt Tuning for Text Summarization|
|------|--------|
| Background | Abstractive summarization models aim to generate shorter versions (summaries) of longer documents.<br />General-purpose summaries may not always meet specific user requirements, such as including certain keywords or adhering to length constraints.<br />Controllable text summarization is a sub-field that focuses on generating summaries tailored to user-specific requirements.<br />Existing controllable models prepend control tokens (e.g., length, keywords) to the input document during training to generate controlled summaries during test time.|
| Problems | The paper aims to address the limitations of existing controllable summarization models and explore the possibility of a single model that can be applied in both controlled and uncontrolled modes.<br />The challenge is to develop a model that can generate high-quality summaries with and without control signals while leveraging the benefits of both approaches.  |
|Solutions| 1. The proposed LOTUS model achieves controllable summarization through prompts.<br /><strong>During training:</strong><br />The uncontrolled model learns a latent prompt from the controlled model using a contrastive learning objective.<br /><strong>During test time:</strong>Different prompts can be used to perform controllable and uncontrollable generation.<br /> The model can be applied in both controlled and uncontrolled modes, depending on the availability of control signals.<br /><strong>Experiment:</strong><br />Experiments were conducted in both uncontrolled and controlled modes on datasets such as CNN/DailyMail, XSum, Gigaword, and New York Times.<br />In the uncontrolled mode, LOTUS consistently outperformed strong uncontrolled models.<br /> In the controlled mode, LOTUS generated summaries that could be controlled using prompts with user-specified control signals.|
|Related Works| <strong>1. Large pre-trained Seq2Seq models:</strong><br />1. Previous work has shown that large pre-trained Seq2Seq models, such as Radford et al. (2019), Lewis et al. (2019), Zhang et al. (2020), and Raffel et al. (2020), can generate high-quality summaries.<br /> 2. However, these models are typically focused on general-purpose summarization and do not allow for generating summaries controlled by user-specific requirements.<br /><strong>2. Controllable summarization:</strong><br />1. Controllable summarization, introduced by Fan et al. (2017), aims to enable models to generate summaries controlled by user-specific requirements.<br />2. Previous methods have focused on length control, where users can specify their preferred summary length, and models stop generating at the specified length.<br />3. Fan et al. (2017) proposed using control tokens, such as target summary length and entities, prepended to the input document to guide Seq2Seq models in generating controlled summaries.<br />4. He et al. (2020) extended this idea by considering keywords as a control signal in their CTRL-Sum model, extracting keywords from reference summaries during training and using a BERT-based keyword extraction model during inference when reference summaries are unavailable. <br /> 5. Xu and Lapata (2022) developed a single model for query-focused summarization (QFS) and general-purpose summarization, similar to LOTUS, but their joint modeling approach does not introduce additional model parameters.<br /> <strong>Training objectives conditioned on control signals:</strong> 1. Some approaches have focused on modifying training objectives to be conditioned on control signals.<br />Earle et al. (2021) formulated controllable generation as a reinforcement learning task, providing additional rewards if the model's generation aligns with the control signals. <br /> Carlsson et al. (2022) and Liu et al. (2022) extended pre-training objectives to incorporate control ability.<br />Liu et al. (2022) introduced a length-aware attention mechanism that selects samples with similar lengths based on the length control signal, which can be transferred to downstream tasks.|
