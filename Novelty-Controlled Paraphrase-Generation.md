# `Novelty Controlled Paraphrase Generation with Retrieval Augmented Conditional Prompt Tuning`


| 1. Topic | Novelty Controlled Paraphrase Generation with Retrieval Augmented Conditional Prompt Tuning|
|-----|--------------------------|
| Problem | The task of paraphrase generation involves rephrasing a given text while retaining its meaning, and it has several applications including text simplification, semantic parsing, query re-writing, and data augmentation. However, the task can be challenging, and the level of lexical novelty of generated paraphrases is usually left upon the model to decide, which may result in trivial paraphrases that are not helpful for applications such as data augmentation.|
| Solution | To address these challenges, the authors propose two methods. <br />1. First, they introduce a method called <strong>Retrieval Augmented Prompt Tuning (RAPT)</strong>, which augments prompt tuning with kNN-based retrieved examples. RAPT can enhance the quality of paraphrases while reducing the number of trainable parameters, making it more parameter-efficient than the standard method of fine-tuning all parameters. <br />2.The authors propose a model-agnostic method called <strong>Novelty Conditioned RAPT (NC-RAPT)</strong>, which uses specialized prompts for different levels of novelty to enable novelty-controlled paraphrase generation. NC-RAPT gives users more control over the level of novelty they want in the generated paraphrases, which can generate paraphrases that are more useful for specific applications, such as data augmentation. Overall, these approaches can improve the quality and usefulness of generated paraphrases, which can benefit various natural language processing tasks.