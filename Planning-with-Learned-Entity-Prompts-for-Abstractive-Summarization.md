# `Planning with Learned Entity Prompts for Abstractive Summarization`


| Topic | Planning with Learned Entity Prompts for Abstractive Summarization|
|-----|--------------------------|
| Problems | Generating abstractive summaries that are faithful, coherent, and specific to entities mentioned in the input document is a challenging task for natural language generation models. Existing approaches that rely on sequence-to-sequence models often suffer from issues such as hallucinations and lack of entity-specificity, which can reduce the quality of the generated summaries. |
| Solution | To address these issues, the authors propose a simple yet flexible mechanism to learn an intermediate plan to ground the generation of abstractive summaries. The approach involves appending the target summary with ordered sequences of entities mentioned in the summary, known as entity chains. Transformer-based sequence-to-sequence models are then trained to generate the entity chain and continue generating the summary conditioned on the entity chain and the input. The authors experiment with both pretraining and finetuning with this content planning objective, achieving state-of-the-art performance on XSum and SAMSum in terms of ROUGE. Moreover, by prompting the decoder with a modified content plan that drops hallucinated entities, they outperform state-of-the-art approaches for faithfulness when evaluated automatically and by humans. |
| Introduction | 1.The traditional text summarization process involves building a source representation, learning a summary representation, and synthesizing the output summary text. Common methods involve semantically analyzing the source text, refining the input representation, and grounding the summary generation to the intermediate summary representation. <br /> 2. State-of-the-art neural summarizers use powerful sequence-to-sequence architectures with attention and copy mechanisms, transformer architectures with multi-headed self-attention, and large pretrained conditional language models. However, grounding the summary generation to an intermediate representation has not been achieved in neural summarization, leading to undesired hallucinations in generated summaries. <br /> 3. The paper investigates using entity chains, ordered sequences of entities in the summary, as an intermediate summary representation to better plan and ground the generation of abstractive summaries. The approach involves using transformer-based encoder-decoder models to generate both the entity chain and the summary conditioned on the entity chain and the input. The results show that the approach outperforms regular finetuning in terms of entity specificity and planning in generated summaries on four popular summarization datasets. The approach can also be used for pretraining summarization models and mitigating hallucinations in abstractive summaries by modifying the predicted entity chain to only keep entities seen in the document. <br />|
| Main Contribution | <strong>1. Planned and Grounded Abstractive Summarization:</strong><br /> The FROST objective is introduced as a novel training objective to neural summarization models for content planning with entity chains, and it aims to ground the generation of summaries to the entity chains found in the reference summaries during training. The objective is designed to try to "freeze entity-level information in abstractive summarization with planning," hence the name FROST. The objective is integrated with supervised fine-tuning and self-supervised pre-training objectives without altering the models themselves. <br /><strong >2. Controlled Abstractive Summarization with Entity Chains:</strong><br />It describes the effectiveness of FROST in entity-level content modification for abstractive summaries. Specifically, the authors show how FROST is critical for ensuring faithfulness by enabling the drop-prompt mechanism, which involves dropping out hallucinated entities from the predicted content plan and prompting the decoder with this modified plan to generate faithful summaries. Additionally, the authors demonstrate that FROST enables the generation of summaries with topical and style diversity, by choosing different sets of entities from the source to plan what to discuss in the summary and by reordering entities in the predicted plan to get an equivalent summary with a different entity emphasis. These findings highlight the importance of FROST in enabling more accurate and diverse summarization.|