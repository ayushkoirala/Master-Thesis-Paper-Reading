# `Learning How to Ask: Querying LMs with Mixtures of Soft Prompts`
paper link : https://arxiv.org/abs/2104.06599

|Topic | Learning How to Ask: Querying LMs with Mixtures of Soft Prompts|
|-----|-------|
|Problems | The problem addressed in the paper is how to effectively query pretrained language models (LMs) in order to elicit desired factual and commonsense knowledge. While LMs have proven to provide useful representations for various NLP tasks, extracting specific information from them can be challenging. Previous approaches relied on manually created prompts or prompt sets generated through mining and paraphrasing methods. However, these methods may not efficiently capture the desired knowledge or cover a wide range of possible queries. The authors propose finding a way to tune prompts using gradient descent to better elicit the desired type of knowledge from LMs.|
|Solution | The authors introduce the concept of "soft prompts" that allow for more expressive and flexible querying of LMs. Instead of treating prompts as sequences of actual English words, soft prompts represent words as continuous vectors, allowing for adjustments and emphasis on specific words or dimensions. Soft prompts enable the optimization process and offer more control over the information extracted from the LMs.<br />To demonstrate the effectiveness of soft prompts, the authors propose learning a mixture of soft prompts for querying LMs. They conduct experiments on several cloze language models, training prompts to complete factual and commonsense relations from three datasets. The performance of the proposed method is evaluated by comparing it to previous approaches on held-out examples.<br />The results show that the mixture of soft prompts significantly outperforms previous methods, even when initialized randomly. The authors conclude that language models possess more knowledge than previously realized, and the key lies in formulating the right queries. By leveraging gradient descent and the flexibility of soft prompts, the proposed approach improves the accuracy and coverage of information retrieval from LMs, potentially advancing their use as approximate knowledge bases.|
