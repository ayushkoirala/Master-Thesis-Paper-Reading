`Visconde: Multi-document QA with GPT-3 and Neural Reranking`
Link: 

|Topic |Visconde: Multi-document QA with GPT-3 and Neural Reranking |
|-------|-----------------|
|Problem Statement |The problem addressed in the paper "Visconde: Multi-document QA with GPT-3 and Neural Reranking" is the limitation of existing question-answering (QA) models that are designed to work with short contexts, such as a single paragraph. In many real-world scenarios, the required information to answer a question is spread across multiple documents or long documents. The authors highlight that the existing QA models based on a retriever and a reader component or using Transformers for long sequences may not be effective in handling longer sequences, such as documents with hundreds of pages. Therefore, there is a need to develop a QA system that can effectively handle multi-document QA tasks.|
|Soltuion |The proposed solution in the paper is Visconde, a QA system that combines a state-of-the-art retriever and a few-shot chain-of-thought (CoT) approach to induce a language model to generate answers as a generative reader. The system is designed to handle multi-document QA tasks by first using a multi-stage pipeline with BM25 and a monoT5 reranker to select candidate documents as the retriever. The reader component utilizes GPT-3 in a few-shot setting, where it reasons over the retrieved records to produce an answer. The authors introduce CoT by asking the model to explain how the evidence documents can answer the question.|
|Methodology |<strong>1. Question Decomposition:</strong><br />In this step, the system utilizes GPT-3 (text-davinci-002) with five in-context examples for question decomposition. The purpose of question decomposition is to break down complex questions into subquestions. The model generates subquestions (Q1, Q2, etc.) based on the user question (Q) by using a few-shot learning approach. The five in-context examples, randomly selected from the StrategyQA dataset's training set, provide the model with guidance for decomposing the question. <br /><strong>2. Document Retrieval:</strong><br />The document retrieval step involves three main sub-steps:<br /><strong>a. Document Indexing:</strong><br />An inverted index is created using Pyserini, which is a tool for working with the Anserini information retrieval toolkit. The inverted index allows for efficient searching and retrieval of relevant documents.<strong>b. Candidate Retrieval:</strong><br />The Pyserini implementation of the BM25 algorithm is used to retrieve candidate documents. BM25 is a ranking function commonly used in information retrieval to assess the relevance of documents based on the query terms.<br /><strong>c. Document Reranking:</strong>The top-1000 candidate documents retrieved in the previous step are reranked using a sequence-to-sequence model called monoT5. The monoT5 model is an adaptation of the T5 model and is designed specifically for reranking documents. It takes the document and the query as input and applies a softmax function to the logits calculated by T5 for the tokens "true" and "false". The log probability of the "true" token serves as the document relevance score. The reranked list of documents is then obtained based on these relevance scores.<br /><strong>3.Aggregation:<br />The aggregation step utilizes GPT-3 (text-davinci-002) as a few-shot learner. The goal is to generate reasoning steps and provide a final answer. The effectiveness of the language model is enhanced by inducing it to generate reasoning steps before answering a question. The Chain-of-Thought (CoT) technique is used to achieve this. In the prompt given to GPT-3, each example consists of a list of context documents, a question, an evidence paragraph, and the answer. The context documents for the target example are selected from the top-k documents obtained in the document retrieval step. When the question is decomposed, the top-k documents from each subquestion are used. For the target example, an evidence paragraph is not provided, and GPT-3 is tasked with generating it along with the final answer.|